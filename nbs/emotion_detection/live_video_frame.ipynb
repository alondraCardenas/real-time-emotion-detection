{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9722d4-1517-4a0f-b65a-a406dd782212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "from imutils.video import VideoStream\n",
    "from fastai.vision import *\n",
    "import imutils\n",
    "import argparse\n",
    "import time\n",
    "import dlib\n",
    "import warnings\n",
    "from torch.serialization import SourceChangeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=SourceChangeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808e2de4-ba64-4399-a21c-3b630d53a5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f', '--fff'], dest='fff', nargs=None, const=None, default='1', type=None, choices=None, help='a dummy argument to fool ipython', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"--save\", dest=\"save\", action = \"store_true\")\n",
    "ap.add_argument(\"--no-save\", dest=\"save\", action = \"store_false\")\n",
    "ap.set_defaults(save = False)\n",
    "ap.add_argument(\"--savedata\", dest=\"savedata\", action = \"store_true\")\n",
    "ap.add_argument(\"--no-savedata\", dest=\"savedata\", action = \"store_false\")\n",
    "ap.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f99e46-4cf6-408a-935f-b621451594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.set_defaults(savedata = False)\n",
    "args = vars(ap.parse_args())\n",
    "path = '/Users/alondracardenas/desktop'\n",
    "learn = load_learner(path, 'export (1).pkl')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "vs = VideoStream(src=0).start()\n",
    "start = time.perf_counter()\n",
    "data = []\n",
    "time_value = 0\n",
    "EYE_AR_THRESH = 0.20\n",
    "EYE_AR_CONSEC_FRAMES = 10\n",
    "COUNTER = 0\n",
    "def eye_aspect_ratio(eye):\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\treturn ear\n",
    "def data_time(time_value, prediction, probability, ear):\n",
    "    current_time = int(time.perf_counter()-start)\n",
    "    if current_time != time_value:\n",
    "        data.append([current_time, prediction, probability, ear])\n",
    "        time_value = current_time\n",
    "    return time_value\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "if args[\"save\"]:\n",
    "    out = cv2.VideoWriter(path + \"liveoutput.avi\", cv2.VideoWriter_fourcc('M','J','P','G'), 10, (450,253))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7873e39c-da94-4158-9ff0-82b0c43b8479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_coord = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "    for coords in face_coord:\n",
    "        X, Y, w, h = coords\n",
    "        H, W, _ = frame.shape\n",
    "        X_1, X_2 = (max(0, X - int(w * 0.3)), min(X + int(1.3 * w), W))\n",
    "        Y_1, Y_2 = (max(0, Y - int(0.3 * h)), min(Y + int(1.3 * h), H))\n",
    "        img_cp = gray[Y_1:Y_2, X_1:X_2].copy()\n",
    "        prediction, idx, probability = learn.predict(Image(pil2tensor(img_cp, np.float32).div_(225)))\n",
    "        cv2.rectangle(\n",
    "                img=frame,\n",
    "                pt1=(X_1, Y_1),\n",
    "                pt2=(X_2, Y_2),\n",
    "                color=(128, 128, 0),\n",
    "                thickness=2,\n",
    "            )\n",
    "        rect = dlib.rectangle(X, Y, X+w, Y+h)\n",
    "    \n",
    "        #writes emotion on frame\n",
    "        cv2.putText(frame, str(prediction), (10, frame.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (225, 255, 255), 2)\n",
    "        \n",
    "        #Read emoji, resize, create mask   \n",
    "        if(str(prediction) == \"happy\"):\n",
    "             emoji = cv2.imread('happy_emoji.png')\n",
    "        elif(str(prediction) == \"sad\"):\n",
    "             emoji = cv2.imread('sad_emoji.png')\n",
    "        elif(str(prediction) == \"neutral\"):\n",
    "            emoji = cv2.imread('neutral_emoji.png')\n",
    "        elif(str(prediction) == \"angry\"):\n",
    "             emoji = cv2.imread('angry_emoji.png')\n",
    "        elif(str(prediction) == \"surprise\"):\n",
    "             emoji = cv2.imread('surprised_emoji.png')\n",
    "\n",
    "        emoji = cv2.resize(emoji,(100, 100))\n",
    "        emoji2gray = cv2.cvtColor(emoji, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(emoji2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Region of Image (ROI), where we want to insert emoji\n",
    "        roi = frame[-100-10:-10, -100-10:-10]\n",
    "        #roi = frame[Y_1:Y_2,X_1:X_2]\n",
    "        \n",
    "        # Set an index of where the mask is\n",
    "        roi[np.where(mask)] = 0\n",
    "        roi += emoji\n",
    "        \n",
    "     \n",
    "        cv2.imshow('WebCam', frame)\n",
    "\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                cv2.putText(frame, \"Distracted\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        else:\n",
    "            COUNTER = 0\n",
    "        cv2.putText(frame, \"Eye Ratio: {:.2f}\".format(ear), (250, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        time_value = data_time(time_value, prediction, probability, ear)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if args[\"save\"]:\n",
    "        out.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\t\t\n",
    "if args[\"savedata\"]:\n",
    "    df = pd.DataFrame(data, columns = ['Time (seconds)', 'Expression', 'Probability', 'EAR'])\n",
    "    df.to_csv(path+'/exportlive.csv')\n",
    "    print(\"data saved to exportlive.csv\")\n",
    "vs.stop()\n",
    "if args[\"save\"]:\n",
    "    print(\"done saving video\")\n",
    "    out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43cd20-f7f1-4b95-94d1-966401209ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
