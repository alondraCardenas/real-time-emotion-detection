{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224eb713-f443-45ac-a9ca-bcfb3f2c6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the opencv library\n",
    "import cv2\n",
    "\n",
    "\n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# used for accessing url to download files\n",
    "import urllib.request as urlreq\n",
    "\n",
    "# used to access local directory\n",
    "import os\n",
    "\n",
    "# used to plot our images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# used to change image size\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9ae838-a818-4721-914b-1cadb2c55a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image.jpg', <http.client.HTTPMessage at 0x7f83774e78e0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save face detection algorithm's url in haarcascade_url variable\n",
    "haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "# save face detection algorithm's name as haarcascade\n",
    "haarcascade = \"haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "# create an instance of the Face Detection Cascade Classifier\n",
    "detector = cv2.CascadeClassifier(haarcascade)\n",
    "\n",
    "\n",
    "# save facial landmark detection model's url in LBFmodel_url variable\n",
    "LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
    "\n",
    "# save facial landmark detection model's name as LBFmodel\n",
    "LBFmodel = \"lbfmodel.yaml\"\n",
    "\n",
    "# create an instance of the Facial landmark Detector with the model\n",
    "landmark_detector  = cv2.face.createFacemarkLBF()\n",
    "landmark_detector.loadModel(LBFmodel)\n",
    "\n",
    "# save picture's url in pics_url variable\n",
    "pics_url = \"https://s.hdnux.com/photos/51/23/24/10827008/3/1200x0.jpg\"\n",
    "\n",
    "# save picture's name as pic\n",
    "pic = \"image.jpg\"\n",
    "\n",
    "# download picture from url and save locally as image.jpg\n",
    "urlreq.urlretrieve(pics_url, pic)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73abfbff-9a8f-4866-b06b-b7d0ea212b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_on_frame(frame):\n",
    "    #make frame gray\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #detect face & draw square around it\n",
    "    #Detect faces using the haarcascade classifier on the \"grayscale image\"\n",
    "    faces = detector.detectMultiScale(gray)\n",
    "        \n",
    "    for face in faces:\n",
    "        #save the coordinates in x, y, w, d variables\n",
    "        (x,y,w,d) = face\n",
    "        # Draw a white coloured rectangle around each face using the face's coordinates\n",
    "        cv2.rectangle(frame,(x,y),(x+w, y+d),(255, 255, 255), 2)\n",
    "        \n",
    "    #find landmarks on face in frame\n",
    "    _, landmarks = landmark_detector.fit(gray, faces)\n",
    "            \n",
    "    #draw on the landmarks\n",
    "    for landmark in landmarks:\n",
    "        for x,y in landmark[0]:\n",
    "            #display landmarks w/ white in BGR and thickness 1\n",
    "            cv2.circle(frame,(int(x), int(y)), 1, (255, 255, 255), 1)\n",
    "            \n",
    "    return frame\n",
    "\n",
    "\n",
    "#pass in image to test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046f565a-bf1e-4dd9-a421-6975f4acf520",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    drawn_on = draw_on_frame(frame)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # After the loop release the cap object\n",
    "        vid.release()\n",
    "        # Destroy all the windows\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
